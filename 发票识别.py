import streamlit as st
import oss2
import requests
import json
import re
import sys
import io
import re
import json
import zipfile
import pandas as pd
import time
import pandas as pd
from model_generate import RequestAPI

def remove_base64_from_json(data):
    for key in data:
        content = data[key]["result"]["data"]["content"]
        index = content.find('[IM0]')
    if index != -1:
        data[key]["result"]["data"]["content"] = content[:index]
    return data

def parse_invoice(json_data) -> tuple[dict, dict]:
    """
    è§£æå‘ç¥¨ JSON æ•°æ®ï¼Œæå–å‘ç¥¨ä¿¡æ¯
    :param json_path: JSON æ–‡ä»¶è·¯å¾„
    :return: JSON æ ¼å¼çš„è§£æç»“æœå’Œä½¿ç”¨æƒ…å†µ
    """
    prompt = """# ä»»åŠ¡ç›®æ ‡\nä»ç”¨æˆ·ä¸Šä¼ çš„å‘ç¥¨ JSON æ•°æ®ä¸­æå–å‡ºå‘ç¥¨ç±»å‹åˆ¤æ–­ç¬¦ï¼ˆjudgeï¼‰ã€å‘ç¥¨ç¨é¢ï¼ˆtaxï¼‰ã€æ€»é¢ï¼ˆtotalï¼‰ã€å‘ç¥¨å‘ç”Ÿæ—¥æœŸï¼ˆdateï¼‰ã€å‘ç¥¨å·ç ï¼ˆcodeï¼‰å’Œé¡¹ç›®åç§°ï¼ˆitemï¼‰ã€‚\n# å…·ä½“è¦æ±‚\n1. å‘ç¥¨ç§ç±»åˆ¤æ–­ç¬¦åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼šæ™®é€šå‘ç¥¨ã€å¢å€¼ç¨å‘ç¥¨ã€é“è·¯ç”µå­å®¢ç¥¨\n2. å‘ç¥¨å‘ç”Ÿæ—¥æœŸæ ¼å¼ä¸ºï¼šYYYYå¹´MMæœˆDDæ—¥ï¼Œä¸åŒ…å«å…·ä½“æ—¶é—´;å¦‚æœå‘ç¥¨ç±»å‹ä¸ºé“è·¯ç”µå­å®¢ç¥¨ï¼Œè¦é€‰å–è½¦ç¥¨å‡ºå‘æ—¶é—´ï¼ˆä¸åŒ…å«å…·ä½“æ—¶é—´ï¼‰\n3. å‘ç¥¨ç¨é¢ï¼šè‹¥å‘ç¥¨ä¸Šä¸åŒ…å«ç¨é¢ï¼Œåˆ™å¡«å†™ä¸º0\n5. é¡¹ç›®åç§°ï¼šç»“åˆå‘ç¥¨ç±»å‹åˆ¤æ–­ç¬¦ï¼ˆjudgeï¼‰è¿›è¡Œåˆ¤æ–­ï¼Œè‹¥ä¸ºé“è·¯ç”µå­å®¢ç¥¨ï¼Œåˆ™å¡«å†™â€œç«è½¦ç¥¨â€ï¼›å¦åˆ™å¡«å†™å‘ç¥¨ä¸Šçš„â€œé¡¹ç›®åç§°â€ï¼Œå¹¶ç”¨ç©ºæ ¼ä»£æ›¿â€œ*â€ï¼›å¦‚æœé¡¹ç›®åç§°å­˜åœ¨å¤šè¡Œï¼Œåˆ™å°†å„è¡Œé¡¹ç›®åç§°ä»¥åŠè§’é€—å·â€œ,â€åˆ†å‰²\n6.åœ¨æå–å‘ç¥¨å·ç æ—¶ï¼Œå…ˆå¿½ç•¥æœºå™¨ç¼–å·å’Œæ ¡éªŒç ï¼›æ³¨æ„å‘ç¥¨å·ç ä¸ºçº¯æ•°å­—ï¼Œä¸åŒ…å«ç‰¹æ®Šç¬¦å·ï¼ˆ*ï¼‰æˆ–è€…å­—æ¯(Aåˆ°Z)ã€‚å¦‚æœä¿¡æ¯åŒ…æ‹¬å‘ç¥¨ä»£ç å’Œå‘ç¥¨å·ç ï¼Œåˆ™éœ€è¦æå–çš„å†…å®¹code=å‘ç¥¨ä»£ç +å‘ç¥¨å·ç \n# ä»¥ä¸‹æ˜¯ç”¨æˆ·ä¸Šä¼ çš„å‘ç¥¨ JSON æ•°æ®"""
    api = RequestAPI()
    rep= api.generate_by_modelscope(prompt=prompt,json_data=json_data, stream=True,model="deepseek-chat")
    try:
        return json.loads(rep)
    except json.JSONDecodeError:
        control=r"[(.*?)]"
        matches= re.search(control, rep, re.DOTALL)
        rep1 = matches.group(1) if matches else "No content found"
        return json.loads(rep1)

# é˜¿é‡Œäº‘ OSS é…ç½®
auth = oss2.Auth('LTAI5t9kZL1yweMWkkY56ArR', 'Rnbl5EaBDjIgJ3pUuP3nMIROITP677')
# ä¿®æ”¹ä¸ºå­˜å‚¨æ¡¶å¯¹åº”çš„æ­£ç¡®ç«¯ç‚¹
bucket = oss2.Bucket(auth, 'http://oss-cn-shanghai.aliyuncs.com', 'oss-pai-3l4o7vcoebkqt34f32-cn-shanghai')
# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å‘ç¥¨è¯†åˆ«",
    page_icon="ğŸ“š",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“š RSMå‘ç¥¨å¡«å†™åŠ©æ‰‹")

# è·å–token
def get_token():
    url = 'https://www.streams7.com/api/auth/login'
    headers = {
        'Content-Type': 'application/json',
        'Cookie': 'auth_token=kig4ljn3UpeYdtnDLBB5HT8G4s9YjSBSeXvN1GMHKGe7eTSw0r7wV5FOSSjvsxlFTGVzLYuz893gSltTGTwxQrGbiwzclCZefX2ipj5pgJ1Rr5fzgU7wY88hLLNWyiEY; auth_token.sig=S70W6N3MdVzUQN-5QiVFjVnMM2A'
    }
    data = {
        "type": "ticket",
        "ticket": "KRXfr0O81EiVAmVb1Rli8LTYC04MXKFy"
    }
    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        token = response.json().get('token')
        return token
    except requests.exceptions.HTTPError as http_err:
        st.error(f"HTTP error occurred while getting token: {http_err}")
    except Exception as err:
        st.error(f"Other error occurred while getting token: {err}")
    return None


# æ–‡æ¡£è§£æz
def analyze_document(token, pdf_url):
    url = 'https://www.streams7.com/api/search/service/document-analyze'
    headers = {
        'sec-ch-ua-platform': '"macOS"',
        'Referer': 'https://rsm.streams7.com/knowledge_base/chat',
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36',
        'accept': 'text/event-stream',
        'sec-ch-ua': '"Chromium";v="134", "Not:A-Brand";v="24", "Google Chrome";v="134"',
        'Content-Type': 'application/json',
        'sec-ch-ua-mobile': '?0',
        'Authorization': f'Bearer {token}'
    }
    data = {
        "document": {
            "url": pdf_url
        }
    }
    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError as http_err:
        st.error(f"HTTP error occurred while analyzing document: {http_err}")
    except Exception as err:
        st.error(f"Other error occurred while analyzing document: {err}")
    return None

##å¤„ç†é€»è¾‘
## ç”Ÿæˆé™„ä»¶ä¸€
def json_to_dataframe1(json_data):
    data = []
    for i, item in enumerate(json_data["outputList"], start=1):
        # åºå·
        serial_number = i
        # å‘ç”Ÿæ—¥æœŸ
        date = item["date"]
        # è´­è´§æ–¹ï¼ˆå‘ç¥¨æŠ¬å¤´ï¼‰
        if item["judge"] == "é“è·¯ç”µå­å®¢ç¥¨":
            invoice_title = "ä¸é€‚ç”¨"
        else:
            invoice_title = "å®¹è¯šä¼šè®¡å¸ˆäº‹åŠ¡æ‰€ï¼ˆç‰¹æ®Šæ™®é€šåˆä¼™ï¼‰ä¸Šæµ·åˆ†æ‰€"
        # ç¥¨æ®é‡‘é¢
        ticket_amount = item["total"]
        # è¿›é¡¹ç¨é¢
        if item["judge"] == "æ™®é€šå‘ç¥¨":
            input_tax = 0
        elif item["judge"] == "å¢å€¼ç¨å‘ç¥¨":
            input_tax = item["tax"]
        elif item["judge"] == "é“è·¯ç”µå­å®¢ç¥¨":
            input_tax = round(item["total"] / 1.09 * 0.09,2)
        # è´¹ç”¨æ‘˜è¦å’Œç¥¨æ®ç§ç±»
        item_str = item["item"]
        if re.search(r'ä½å®¿æœåŠ¡|ä»£è®¢ä½å®¿|ä½å®¿è´¹', item_str):
            expense_summary = "ä½å®¿è´¹"
            ticket_type = "ä½å®¿ç¥¨"
            if re.search(r'ä»£è®¢ä½å®¿', item_str):
                remark = "æºç¨‹/é£çŒªç­‰é…’åº—å‘ç¥¨"
            else:
                remark = ""
        elif re.search(r'å›½å†…èˆªç©ºæ—…å®¢è¿è¾“æœåŠ¡|ä»£è®¢æœºç¥¨', item_str):
            expense_summary = "äº¤é€šè´¹"
            if re.search(r'ä»£è®¢æœºç¥¨', item_str):
                ticket_type = "å…¶ä»–è¿è¾“æœåŠ¡ç”µå­å‘ç¥¨"
                remark = "æºç¨‹/é£çŒªç­‰æœºç¥¨å‘ç¥¨"
            else:
                ticket_type = "æœºç¥¨"
                remark = ""
        elif re.search(r'å®¢è¿æœåŠ¡è´¹', item_str):
            expense_summary = "äº¤é€šè´¹"
            ticket_type = "æ‰“è½¦è½¯ä»¶å‘ç¥¨"
            remark = ""
        elif re.search(r'é¤é¥®æœåŠ¡', item_str):
            expense_summary = "é¤è´¹"
            ticket_type = "é¤ç¥¨"
            remark = ""
        else:
            if item["judge"] == "é“è·¯ç”µå­å®¢ç¥¨":
                expense_summary = "äº¤é€šè´¹"
                ticket_type = "ç«è½¦ç¥¨"
            else:
                expense_summary = item["item"]
                ticket_type = item["judge"]
            remark = ""

        data.append([serial_number, date, expense_summary, invoice_title,
                     ticket_type, ticket_amount, input_tax, remark])
    columns = ["åºå·", "å‘ç”Ÿæ—¥æœŸ", "è´¹ç”¨æ‘˜è¦", "è´­è´§æ–¹ï¼ˆå‘ç¥¨æŠ¬å¤´ï¼‰",
               "ç¥¨æ®ç§ç±»", "ç¥¨æ®é‡‘é¢", "è¿›é¡¹ç¨é¢", "å¤‡æ³¨"]
    df = pd.DataFrame(data, columns=columns)
    return df

## ç”Ÿæˆé™„ä»¶äºŒ
def json_to_dataframe2(json_data):
    data = []
    for i, item in enumerate(json_data["outputList"], start=1):
        item_str = item["item"]
        # åºå·
        serial_number = i
        # å‘ç”Ÿæ—¥æœŸ
        date = item["date"]
        # è´­è´§æ–¹ï¼ˆå‘ç¥¨æŠ¬å¤´ï¼‰
        if item["judge"] == "é“è·¯ç”µå­å®¢ç¥¨":
            invoice_title = "ä¸é€‚ç”¨"
        else:
            invoice_title = "å®¹è¯šä¼šè®¡å¸ˆäº‹åŠ¡æ‰€ï¼ˆç‰¹æ®Šæ™®é€šåˆä¼™ï¼‰ä¸Šæµ·åˆ†æ‰€"
        # ç¥¨æ®é‡‘é¢
        ticket_amount = item["total"]
        # è¿›é¡¹ç¨é¢
        if item["judge"] == "æ™®é€šå‘ç¥¨":
            input_tax = 0
        elif item["judge"] == "å¢å€¼ç¨å‘ç¥¨":
            input_tax = item["tax"]
        elif item["judge"] == "é“è·¯ç”µå­å®¢ç¥¨":
            input_tax = round(item["total"] / 1.09 * 0.09,2)
        # ç¥¨æ®ç§ç±»
        if re.search(r'ä½å®¿æœåŠ¡|ä»£è®¢ä½å®¿', item_str):
            ticket_type = "ä½å®¿ç¥¨"
            if re.search(r'ä»£è®¢ä½å®¿', item_str):
                remark = "æºç¨‹/é£çŒªç­‰é…’åº—å‘ç¥¨"
            else:
                remark = ""
        elif re.search(r'å›½å†…èˆªç©ºæ—…å®¢è¿è¾“æœåŠ¡|ä»£è®¢æœºç¥¨', item_str):
            if re.search(r'ä»£è®¢æœºç¥¨', item_str):
                ticket_type = "å…¶ä»–è¿è¾“æœåŠ¡ç”µå­å‘ç¥¨"
                remark = "æºç¨‹/é£çŒªç­‰æœºç¥¨å‘ç¥¨"
            else:
                ticket_type = "æœºç¥¨"
                remark = ""
        elif re.search(r'å®¢è¿æœåŠ¡è´¹', item_str):
            ticket_type = "æ‰“è½¦è½¯ä»¶å‘ç¥¨"
            remark = ""
        elif re.search(r'é¤é¥®æœåŠ¡', item_str):
            ticket_type = "é¤ç¥¨"
            remark = ""
        else:
            if item["judge"] == "é“è·¯ç”µå­å®¢ç¥¨":
                ticket_type = "ç«è½¦ç¥¨"
            else:
                ticket_type = item["judge"]
            remark = ""
        number_bx=""
        data.append([serial_number, date, invoice_title,ticket_type, 
                    ticket_amount, input_tax,number_bx,remark])

    columns = ["åºå·", "å‘ç”Ÿæ—¥æœŸ", "è´­è´§æ–¹ï¼ˆå‘ç¥¨æŠ¬å¤´ï¼‰","ç¥¨æ®ç§ç±»", 
            "ç¥¨æ®é‡‘é¢", "è¿›é¡¹ç¨é¢", "æŠ¥é”€å•å·","å¤‡æ³¨"]
    df = pd.DataFrame(data, columns=columns)
    # åˆ é™¤è¿›é¡¹ç¨é¢ä¸º 0 çš„è¡Œ
    df = df[(df["è¿›é¡¹ç¨é¢"] != 0) & df["ç¥¨æ®ç§ç±»"].isin(["ç«è½¦ç¥¨", "æ‰“è½¦è½¯ä»¶å‘ç¥¨", "æœºç¥¨", "å…¶ä»–è¿è¾“æœåŠ¡ç”µå­å‘ç¥¨"])]
    # é‡æ–°æ’åºåºå·
    df = df.reset_index(drop=True)
    df["åºå·"] = df.index + 1
    return df

## ç”Ÿæˆé™„ä»¶ä¸‰
def json_to_dataframe3(json_data):
    data = []
    for i, item in enumerate(json_data["outputList"], start=1):
        # åºå·
        serial_number = i
        # æ—¥æœŸ
        date = item["date"]
        # å‘ç¥¨ä»£ç 
        invoice_id=item["code"][0:12]
        # å‘ç¥¨å·ç 
        invoice_number=item["code"][12:]
        # å¼€ç¥¨å†…å®¹
        content=item["item"]
        if content=='ä½å®¿è´¹' or content=='ä½å®¿æœåŠ¡':
            content="ä½å®¿æœåŠ¡ ä½å®¿è´¹"
        elif content=='è¿è¾“æœåŠ¡|å®¢è¿æœåŠ¡è´¹':
            content="è¿è¾“æœåŠ¡ å®¢è¿æœåŠ¡è´¹"
        elif content=='é¤é¥®æœåŠ¡':
            content="é¤é¥®æœåŠ¡ é¤é¥®æœåŠ¡"
        else:
            content = content.replace(",", "\n")
        # é‡‘é¢
        ticket_amount=item["total"]
        # æŠ¥é”€äººå’ŒæŠ¥é”€å•å·
        people=''
        number_bx=''
        
        data.append([serial_number, date, invoice_id,invoice_number,content,
                     ticket_amount, people,number_bx])

    columns = ["åºå·", "æ—¥æœŸ", "å‘ç¥¨ä»£ç ","å‘ç¥¨å·ç ", "å¼€ç¥¨å†…å®¹", 
               "é‡‘é¢", "æŠ¥é”€äºº", "æŠ¥é”€å•å·"]
    df = pd.DataFrame(data, columns=columns)
    return df

def main():
    # ä¸Šä¼ å¤šä¸ª PDF æ–‡ä»¶
    uploaded_files = st.file_uploader("ç¬¬ä¸€æ­¥ï¼šè¯·ä¸Šä¼ å‘ç¥¨æ–‡ä»¶",type=["pdf"], accept_multiple_files=True)
    if uploaded_files:
        file_count = len(uploaded_files)
        pdf_count = sum(1 for f in uploaded_files if f.type == "application/pdf")
        image_count = file_count - pdf_count
        st.success(f"æˆåŠŸä¸Šä¼  {file_count} ä¸ªæ–‡ä»¶ï¼ˆ{pdf_count} ä¸ª PDFï¼‰")
    # æ·»åŠ æŒ‰é’®
    analyze_button = st.button("ç¬¬äºŒæ­¥ï¼šç‚¹å‡»è§£æå‘ç¥¨æ–‡ä»¶")
    
    if uploaded_files and analyze_button:
        token = get_token()
        if token:
            all_results = {}
            for uploaded_file in uploaded_files:
                # ä¸Šä¼ æ–‡ä»¶åˆ° OSS
                oss_key = f'uploads/{uploaded_file.name}'
                result = bucket.put_object(oss_key, uploaded_file)
                if result.status == 200:
                    # ç”Ÿæˆå¸¦ç­¾åçš„ URL
                    pdf_url = bucket.sign_url('GET', oss_key, 3600)  # ç­¾å URL æœ‰æ•ˆæœŸä¸º 3600 ç§’
                    # è§£ææ–‡æ¡£
                    result = analyze_document(token, pdf_url)
                    if result:
                        all_results[uploaded_file.name] = result
                    time.sleep(0.5)
            if all_results:
                jsonfiles = {"outputList": []}
                # å°†ç»“æœè½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
                contents = []
                for item in all_results.values():
                    contents.append(item["result"]["data"]["content"])
                all_results=remove_base64_from_json(all_results)
                # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼ŒåŒ¹é… [IM0]:data:image/ å¼€å¤´çš„è¡ŒåŠåç»­æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬æ¢è¡Œç¬¦ï¼‰
                pattern = re.compile(r'\[IM0\]:data:image/.*', re.DOTALL)

                for pdf_key in all_results:
                    # æå– content å†…å®¹
                    content = all_results[pdf_key]['result']['data']['content']
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢åŒ¹é…åˆ°çš„å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²
                    cleaned_content = re.sub(pattern, '', content)
                    # æ›´æ–°å­—å…¸ä¸­çš„ content
                    all_results[pdf_key]['result']['data']['content'] = cleaned_content
                for i in contents:
                    json_result= parse_invoice(i)
                    jsonfiles["outputList"].append(json_result)
                json_str = json.dumps(all_results, indent=2,ensure_ascii=False)
                #st.download_button(
                        #label="ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½EXCELå‹ç¼©åŒ…",
                        #data=json_str,
                        #file_name="all_results.json",
                        #mime="application/json",  # æŒ‡å®š MIME ç±»å‹
                    #)
                # åˆ›å»ºä¸‹è½½æŒ‰é’®åˆ—
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w') as zipf:
                        # å¤„ç† col2 çš„æ–‡ä»¶
                        csv_1 = json_to_dataframe1(jsonfiles)
                        excel_buffer_1 = io.BytesIO()
                        csv_1.to_excel(excel_buffer_1, index=False, engine='openpyxl')
                        excel_buffer_1.seek(0)
                        zipf.writestr("é™„ä»¶1_è´¹ç”¨å¼€æ”¯æ˜ç»†è¡¨_XXX_XXXå¹´åº¦äº§å“å®¡è®¡ã€æ¸…ç®—å®¡è®¡ã€äº§å“éªŒèµ„åŠRWAé‰´è¯.xlsx",
                                    excel_buffer_1.getvalue())

                        # å¤„ç† col3 çš„æ–‡ä»¶
                        csv_2 = json_to_dataframe2(jsonfiles)
                        if not csv_2.empty:
                            excel_buffer_2 = io.BytesIO()
                            csv_2.to_excel(excel_buffer_2, index=False, engine='openpyxl')
                            excel_buffer_2.seek(0)
                            zipf.writestr("é™„ä»¶2_å¯æŠµæ‰£äº¤é€šè´¹æ˜ç»†è¡¨_XXX_XXXå¹´åº¦å…¬å‹ŸåŠä¸“æˆ·äº§å“å®¡è®¡.xlsx",
                                        excel_buffer_2.getvalue())

                        # å¤„ç† col4 çš„æ–‡ä»¶
                        csv_3 = json_to_dataframe3(jsonfiles)
                        excel_buffer_3 = io.BytesIO()
                        csv_3.to_excel(excel_buffer_3, index=False, engine='openpyxl')
                        excel_buffer_3.seek(0)
                        zipf.writestr("é™„ä»¶3_ç”µå­å‘ç¥¨ç™»è®°è¡¨_XXX_XXXå¹´åº¦å…¬å‹ŸåŠä¸“æˆ·äº§å“å®¡è®¡.xlsx",
                                    excel_buffer_3.getvalue())

                    zip_buffer.seek(0)
                    st.download_button(
                        label="ä¸‹è½½å‹ç¼©åŒ…",
                        data=zip_buffer,
                        file_name="æ‰€æœ‰é™„ä»¶.zip",
                        mime="application/zip"
                    )

if __name__ == "__main__":
    main()

# ä¾§è¾¹æ è¯´æ˜
with st.sidebar:
    st.header("æ“ä½œæŒ‡å—")
    st.markdown("""
    **1.ä¸Šä¼ å‘ç¥¨æ–‡ä»¶**
    """)
    st.markdown("""
    **2.ç‚¹å‡»è§£ææ–‡æ¡£æŒ‰é’®**
    """)
    st.markdown("""
    **3.ä¸‹è½½excelæ–‡ä»¶**
    """)
    st.header("""
    **æ³¨æ„**
    """)
    st.markdown("""
    **1ï¼‰å¦‚æœæ¼ä¼ å‘ç¥¨ï¼Œåˆ™ç»§ç»­è¡¥å……ä¸Šä¼ ï¼Œæœ€ç»ˆç‚¹å‡»è§£æå¹¶ä¸‹è½½excelå³å¯**
    """)
